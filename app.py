import streamlit as st
# from transformers import VitsModel, AutoTokenizer
# import torch
# import scipy.io.wavfile
# import tempfile
import os
# import base64
from datetime import datetime
import json
# import speech_recognition as sr
import requests
from smolagents import OpenAIServerModel, ToolCallingAgent, Tool

# os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

# try:
#     import streamlit.watcher.local_sources_watcher
#     def patched_get_module_paths(module):
#         try:
#             if hasattr(module, '__path__'):
#                 return list(module.__path__)
#             return []
#         except Exception:
#             return []
#     streamlit.watcher.local_sources_watcher.get_module_paths = patched_get_module_paths
# except ImportError:
#     pass

# Initialiser modÃ¨le IA Gemini
try:
    model_ai = OpenAIServerModel(
        model_id="gemini-2.0-flash",
        api_base="https://generativelanguage.googleapis.com/v1beta",
        api_key="AIzaSyCQBFGBRT73g-dh0WNO5SfitmxxCOIQKdU"
    )
except Exception as e:
    st.error(f"Erreur initialisation modÃ¨le Gemini: {e}")
    model_ai = None

# DÃ©finir l'outil de recherche web
class SearchWebTool(Tool):
    name = "moroccan_darija_web_search"
    description = "ÙƒÙŠÙ‚Ù„Ø¨ ÙØ§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù„ÙŠ ÙƒÙŠØªØ·Ù„Ø¨Ùˆ ÙØ§Ù„Ø¥Ø¯Ø§Ø±Ø§Øª Ø¨Ø§Ù„Ø¯Ø§Ø±Ø¬Ø© Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ©."
    inputs = {
        "query": {
            "type": "string",
            "description": "Ø´Ù†Ùˆ Ø¨ØºÙŠØªÙŠ ØªÙ‚Ù„Ø¨ Ø¹Ù„ÙŠÙ‡ØŒ Ù…Ø«Ù„Ø§: 'Ø´Ù†Ùˆ Ø®Ø§ØµÙ†ÙŠ Ù†ÙˆØ¬Ø¯ Ù„Ø¬ÙˆØ§Ø² Ø§Ù„Ø³ÙØ± Ø§Ù„Ù…ØºØ±Ø¨'"
        }
    }
    output_type = "string"

    def forward(self, query: str) -> str:
        try:
            api_key ="59987dee629e60fa56510999efde2faecac8beee73bcab5ad1fcea0b6d1244e8"
            response = requests.get(
                "https://serpapi.com/search",
                params={"q": query, "hl": "ar", "gl": "ma", "engine": "google", "api_key": api_key}
            )
            data = response.json()
            results = data.get("organic_results", [])[:3]
            if not results:
                return "Ù…Ø§ Ù„Ù‚ÙŠØªØ´ Ù†ØªØ§Ø¦Ø¬ Ø¯Ø§Ø¨Ø§ØŒ Ø¬Ø±Ø¨ ØªØ³ÙˆÙ„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£Ø®Ø±Ù‰."
            return "\n\n".join(f"{r['title']}\n{r['link']}" for r in results)
        except Exception as e:
            return f"Ø®Ø·Ø£ ÙØ§Ù„Ø¨Ø­Ø«: {str(e)}"

# Agent IA
agent = None
if model_ai:
    try:
        agent = ToolCallingAgent(model=model_ai, tools=[SearchWebTool()])
    except Exception as e:
        st.error(f"Erreur initialisation agent: {e}")

# Config page
st.set_page_config(
    page_title="Ø§Ù„Ù…Ù‚Ø¯Ù…",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

def init_session():
    for key in ['conversation', 'audio_enabled', 'recording', 'audio_data']:
        if key not in st.session_state:
            st.session_state[key] = [] if key == 'conversation' else None if key == 'audio_data' else False

# def text_to_speech(text):
#     ...

# def get_audio_bytes(audio_file):
#     ...

# def base64_to_wav(base64_string):
#     ...

# def recognize_speech(audio_file):
#     ...

def get_ai_response(message, model_type="gemini-2.0-flash"):
    if not agent:
        return "Erreur: agent IA non initialisÃ©."
    try:
        conversation = "\n".join(f"{role}: {msg}" for role, msg, _ in st.session_state.conversation)
        result = agent.run(f"{conversation}\nUser: {message}\nAssistant:")
        return result
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¬ÙˆØ§Ø¨: {str(e)}"

def main():
    init_session()
    st.title("ğŸ¤– Ù…Ù‚Ø¯Ù…  ML")
    st.markdown("---")

    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        model_choice = st.selectbox("ModÃ¨le IA:",["Ù…Ù‚Ø¯Ù… ML","Ø§Ù„Ø¨Ø§Ø´Ø§"], index=3)
        # st.subheader("ğŸ”Š Audio")
        # st.checkbox("Sortie audio", value=True, key='audio_enabled')
        # st.checkbox("EntrÃ©e audio", value=False, key='recording')
        if st.button("ğŸ—‘ï¸ Effacer l'historique"):
            st.session_state.conversation = []
            st.rerun()

    col1, col2 = st.columns([3, 1])
    with col1:
        st.subheader("ğŸ’¬ Conversation")
        for i, (role, message, timestamp) in enumerate(st.session_state.conversation):
            st.markdown(f"**{'Vous' if role == 'user' else 'LM Ù…Ù‚'}** ({timestamp}):")
            st.markdown(message if role == "ai" else f"*{message}*")
            # if role == "ai" and st.session_state.audio_enabled:
            #     if st.button(f"ğŸ”Š Ã‰couter", key=f"audio_{i}"):
            #         audio_file = text_to_speech(message)
            #         if audio_file:
            #             audio_bytes = get_audio_bytes(audio_file)
            #             st.markdown(f"""
            #             <audio controls autoplay>
            #                 <source src="data:audio/wav;base64,{audio_bytes}" type="audio/wav">
            #             </audio>
            #             """, unsafe_allow_html=True)
            #             os.unlink(audio_file)
            st.markdown("---")

    with col2:
        st.subheader("ğŸ“Š Statistiques")
        st.metric("Messages", len(st.session_state.conversation))
        st.metric("ModÃ¨le actuel", model_choice)
        if st.button("ğŸ“¥ Exporter"):
            json_data = json.dumps(st.session_state.conversation, indent=2, ensure_ascii=False)
            st.download_button("TÃ©lÃ©charger JSON", data=json_data, file_name="conversation.json", mime="application/json")

    st.markdown("---")
    st.subheader("âœï¸ Votre message")
    input_method = st.radio("MÃ©thode de saisie:", ["Texte"], horizontal=True, key="input_mode")

    if st.session_state.input_mode == "Texte":
        user_input = st.text_area("Tapez votre message:", height=100, placeholder="Ã‰crivez ici...")
        if st.button("ğŸ“¤ Envoyer") and user_input.strip():
            timestamp = datetime.now().strftime("%H:%M:%S")
            st.session_state.conversation.append(("user", user_input, timestamp))
            with st.spinner("LM Ù…Ù‚Ø¯Ù… rÃ©flÃ©chit..."):
                ai_response = get_ai_response(user_input, model_choice)
                st.session_state.conversation.append(("ai", ai_response, timestamp))
            st.rerun()
    # else:
    #     st.info("ğŸ¤ Enregistrement audio activÃ© (implÃ©mentation JS requise pour navigateur)")
    #     st.warning("Fonction audio Ã  activer manuellement dans la version web.")

    with st.expander("â„¹ï¸ Informations sur lM Ù…Ù‚Ø¯Ù…"):
        st.markdown("""
        ### FonctionnalitÃ©s:
        - Chat en darija marocaine
        - Recherche web (via SerpAPI)
        - Export conversation
        """)

if __name__ == "__main__":
    main()
